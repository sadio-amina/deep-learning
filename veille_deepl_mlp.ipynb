{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7af8ef9",
   "metadata": {},
   "source": [
    "# VEILLE SUR LES METHODES DE DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10a4d0",
   "metadata": {},
   "source": [
    "Réalisez une veille sur le Perceptron Multicouches et expliquez son architecture\n",
    "(couches d’entrée, couches cachées, couches de sortie, couches denses, etc).\n",
    "Quels sont ses hyperparamètres ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31bac2b",
   "metadata": {},
   "source": [
    "Les neurones du perceptron multicouche peuvent étre vu comme une multitude de perceptron connectés entre eux.La particularité topologique\n",
    "de ce réseau est que tous les neurones d’une couche sont connectés à tous les neurones de la couche suivante. Chaque neurones a donc n entrées,\n",
    "n étant le nombre de neurones présent dans la couche précédente, et une sortie qui est envoyée à tous les neurones de la couche suivante.\n",
    "\n",
    "À chaque connexion neuronale est associé un poids W, comme pour les entrées du perceptron. Le calcul de la sortie d’un neurone se fait selon\n",
    "la fonction d’activation qui a été choisie.\n",
    "Le perceptron multicouche est le premier réseau de neurones à avoir trouvé de nombreuses applications pratiques telles que la reconnaissance \n",
    "de fleurs, la détection de fraudes, etc.. Il peut être utilisé pour toutes tâches de classification supervisées. De nos jours, il est l’un des \n",
    "modèles les plus populaires, et est implémenté par de nombreuses librairies telles que TensorFlow, Weka, Scikit-Learn, etc.\n",
    "\n",
    "L'architecture du perceptron multicouches est comme suit :\n",
    "- la première couche appelée couche d'entrée est composée de neurones « transparents » qui n'effectuent aucun calcul mais simplement distribuent\n",
    "leurs entrées à tous les neurones de la couche suivante appelée couche cachée.\n",
    "- les neurones de la couche cachée  reçois les n entrées de la couche d'entrée avec les poids associés. Ici les entrées sont combinées et transformées par des fonctions d'activation non linéaires \n",
    "- les couches de sortie, elles, sont constitués de neurones qui effectuent des opérations de calcul pour produire des sorties, elles sont donc essentielles pour générer les prédictions\n",
    "\n",
    "Les hyperparamètres du perceptron multcouches sont : le nombre de couche, le nombre de neurones par couche, la fonction d'activation, le learning rate, le nombre d'épochs, l'algorithme d'optimisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e09cd",
   "metadata": {},
   "source": [
    "3. Définissez les termes suivants : Fonction d’activation, Propagation,\n",
    "rétropropagation, Loss-function, Descente de gradient, Vanishing gradients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad7f41b",
   "metadata": {},
   "source": [
    "FONCTION D'ACTIVATION \n",
    "Une fonction d’activation est une fonction mathématique utilisé sur un signal. Elle va reproduire le potentiel d’activation que l’on retrouve\n",
    "dans le domaine de la biologie du cerveau humain. Elle va permettre le passage d’information ou non de l’information si le seuil de stimulation\n",
    "est atteint.\n",
    "Par ailleurs, elle sert avant tout à modifier de manière non-linéaire les données. Cette non-linéarité permet de modifier spatialement leur représentation.\n",
    " Concrètement, elle va avoir pour rôle de décider si on active ou non une réponse du neurone. Un neurone ne va faire qu’appliquer la\n",
    "fonction suivante :\n",
    "\n",
    "X = ∑ ( entrée * poids ) + biais\n",
    "\n",
    "C’est sur cette sortie que la fonction d’activation va s’appliquer.\n",
    "Exemples de fonctions d'activations : ReLU, sigmoid, linéaire, tanhH, softmax...\n",
    "########################################################################################################\n",
    "\n",
    "PROPAGATION\n",
    "La propagation (forward propagation ) consiste à faire passer des données d'entrée dans un réseau, dans le sens de la marche, pour générer une sortie. \n",
    "Les données sont  acceptées par les couches cachées et traitées, conformément à la fonction d'activation, et passent à la couche suivante. Le flux de données\n",
    " vers l'avant est conçu pour éviter que les données ne se déplacent de manière circulaire, ce qui ne génère pas de sortie. \n",
    "\n",
    "Au cours de la propagation vers l'avant, la pré-activation et l'activation ont lieu à chaque nœud de la couche cachée et de la couche de sortie d'un réseau neuronal.\n",
    " La fonction de pré-activation est le calcul de la somme pondérée. La fonction d'activation est appliquée, sur la base de la somme pondérée, pour faire circuler le\n",
    " réseau neuronal de manière non linéaire en utilisant un biais.\n",
    "\n",
    "###########################################################################################################\n",
    "RETROPROPAGATION \n",
    "La rétropropagation est utilisée dans les réseaux neuronaux pour améliorer les résultats. Un réseau neuronal est un ensemble de nœuds d'entrée et de sortie connectés.\n",
    "La précision de chaque nœud est exprimée sous la forme d'une fonction de perte (Loss Function), également connue sous le nom de taux d'erreur. \n",
    "\n",
    "La rétropropagation calcule le gradient mathématique, ou la pente, du taux d'erreur par rapport aux autres poids du réseau neuronal. Sur la base de ces calculs, \n",
    "les nœuds du réseau neuronal présentant des taux d'erreur élevés ont moins de poids que les nœuds présentant des taux d'erreur plus faibles, qui ont plus de poids. \n",
    "Les poids déterminent l'influence d'une entrée sur une sortie.\n",
    "\n",
    "################################################################################################################\n",
    "\n",
    "LOSS FUNCTION ( FONCTION DE PERTE )\n",
    "Le réseau neuronal utilise des stratégies d'optimisation telles que la descente de gradient stochastique pour minimiser l'erreur dans l'algorithme. Cette erreur\n",
    " est calculée à l'aide d'une fonction de perte. Elle permet de quantifier la qualité ou la médiocrité des performances du modèle. Ces fonctions sont divisées en deux catégories : la perte de régression et la perte de classification. On distingue deux catégories de fonction de perte :\n",
    "- celle de régression qui est utilisée lorsque nous prédisons des valeurs continues telles que le prix d'une maison ou les ventes d'une entreprise ( Mean \n",
    "Squared Error , Mean Squared Logarithmic Error Loss, Mean Absolute Error Loss...)\n",
    "- celle de classification qui est utilisée dans le contexte de classification binaire ou multiple ( Binary Cross Entropy Loss, Hinge Loss, Categorical Cross Entropy Loss... )\n",
    "\n",
    "#######################################################################################################################\n",
    "\n",
    "DESCENTE DE GRADIENT\n",
    "La descente de gradient est un algorithme qui permet de minimiser la fonction de perte . Il existe 3 types d'algorithmes d'apprentissage par\n",
    "descente de gradient : la descente de gradient par lots,  la descente de gradient stochastique et  la descente de gradient en mini-lot .\n",
    "\n",
    ". Qu’est ce qu’une fonction d’activation ? Donnez des exemples.\n",
    "\n",
    "Une fonction d’activation est une fonction mathématique utilisé sur un signal. Elle va reproduire le potentiel d’activation que l’on retrouve\n",
    "dans le domaine de la biologie du cerveau humain. Elle va permettre le passage d’information ou non de l’information si le seuil de stimulation\n",
    "est atteint.\n",
    "Concrètement, elle va avoir pour rôle de décider si on active ou non une réponse du neurone. Un neurone ne va faire qu’appliquer la\n",
    "fonction suivante :\n",
    "\n",
    "X = ∑ ( entrée * poids ) + biais\n",
    "\n",
    "C’est sur cette sortie que la fonction d’activation va s’appliquer.\n",
    "Exemples de fonctions d'activations : ReLU, sigmoid, linéaire, tanhH, softmax...\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "VANISHING GRADIENTS\n",
    "\n",
    "Lors de la rétropropagation, un réseau neuronal apprend en mettant à jour ses poids et ses  biais afin de réduire la fonction.\n",
    "Dans un réseau présentant un \"vanishing gradients\", les poids ne peuvent pas étre mis à jour, ce qui signifie que le réseau ne peut pas apprendre. En conséquence, les performances du réseau diminueront."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb29b05",
   "metadata": {},
   "source": [
    " Qu’est ce qu’une fonction d’activation ? Donnez des exemples.\n",
    "    \n",
    "FONCTION D'ACTIVATION \n",
    "Une fonction d’activation est une fonction mathématique utilisé sur un signal. Elle va reproduire le potentiel d’activation que l’on retrouve\n",
    "dans le domaine de la biologie du cerveau humain. Elle va permettre le passage d’information ou non de l’information si le seuil de stimulation\n",
    "est atteint.\n",
    "Par ailleurs, elle sert avant tout à modifier de manière non-linéaire les données. Cette non-linéarité permet de modifier spatialement leur représentation.\n",
    " Concrètement, elle va avoir pour rôle de décider si on active ou non une réponse du neurone. Un neurone ne va faire qu’appliquer la\n",
    "fonction suivante :\n",
    "\n",
    "X = ∑ ( entrée * poids ) + biais\n",
    "\n",
    "C’est sur cette sortie que la fonction d’activation va s’appliquer.\n",
    "Exemples de fonctions d'activations : ReLU, sigmoid, linéaire, tanhH, softmax..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a26e12",
   "metadata": {},
   "source": [
    " Définissez et différenciez les notions d’Epochs, d’Iterations et de Batch size.\n",
    "\n",
    "On parle d'Epochs lorsqu'un jeu de donnée entier est passé par les phases de propagation et rétro-propagation par le réseau neuronal une seule fois.\n",
    "Le batch size est un nombre d'échantillons traités avant l'actualisation du modèle.\n",
    "Iteration représente le nombre de batch qu'on a besoin pour compléter une epoch ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7665ca91",
   "metadata": {},
   "source": [
    " Qu’est ce que l’hyper-paramètre learning rate ? Quelles sont les conséquences\n",
    "d’un learning rate trop bas ou trop élevé ?\n",
    "\n",
    "Le learning rate est un hyperparamètre qui contrôle l'ampleur de la modification du modèle en réponse à l'erreur estimée à chaque fois que les poids du modèle\n",
    "sont mis à jour. Une valeur trop faible de learning rate  peut entraîner un long processus d'apprentissage susceptible de se bloquer, tandis qu'une valeur trop élevée peut entraîner l'apprentissage trop rapide d'un ensemble sous-optimal de poids ou un processus d'apprentissage instable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be111d",
   "metadata": {},
   "source": [
    "Définissez la Batch normalization et argumentez son utilisation .\n",
    "\n",
    "La batch normalization est une technique essentielle du deep learning  utilisée pour rendre l'apprentissage des réseaux de neurones plus rapide et stable \n",
    "gràce  à la normalisation des entrées des couches par le recentrage et  la mise en échelle .\n",
    "L'utilisation de la batch normalization procure plusieurs bénéfices au réseau de neurones.\n",
    "En effet, la batch size permet la stabilisation du réseau de neurones car pour chaque batch, le réseau doit s'adapter à une seule plage de \n",
    "données normalisées.Par ailleurs, elle est utilisée en tant que Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7b61eb",
   "metadata": {},
   "source": [
    "Qu'est-ce que l'algorithme d'optimisation d'Adam ?\n",
    "\n",
    "C'est utilisé pour la formation de modèles d'apprentissage profond. Il s'agit d'une extension de la descente de gradient stochastique.\n",
    "Dans cet algorithme, les moyennes courantes des gradients et des seconds moments des gradients sont utilisés. Il est utilisé pour calculer les\n",
    "taux d'apprentissage adaptatifs pour chaque paramètre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed15946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
